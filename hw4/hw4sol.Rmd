---
title: "Biostat 203B Homework 4"
subtitle: Due Mar 18 @ 11:59PM
author: Jiahao Tian
output:
  # ioslides_presentation: default
  html_document:
    toc: true
    toc_depth: 4
---

```{r, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
```

Display machine information:
```{r}
sessionInfo()
```
Load database libraries and the tidyverse frontend:
```{r}
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(lubridate))
suppressPackageStartupMessages(library(miceRanger))
library(kableExtra)
library(SmartEDA)
library(caret)
```

## Q1. Missing data

Through the Shiny app developed in HW3, we observe abundant missing values in the MIMIC-IV ICU cohort we created. In this question, we use multiple imputation to obtain a data set without missing values.

0. Read following tutorials on the R package miceRanger for imputation: <https://github.com/farrellday/miceRanger>, <https://cran.r-project.org/web/packages/miceRanger/vignettes/miceAlgorithm.html>.

    A more thorough book treatment of the practical imputation strategies is the book [*_Flexible Imputation of Missing Data_*](https://stefvanbuuren.name/fimd/) by Stef van Buuren. 

1. Explain the jargon MCAR, MAR, and MNAR.

**Solution:** 


**MCAR** (Missing Completely at Random) is a situation in which some values on a variable of 
interest are unrecorded, but there is no systematic relationship between that missing value and 
the observed variables or any parameter of interest. This is equivalent to claiming that the complete
instances represent a random sample of the population of interest, making a full case analysis impartial.


**MAR** (Missing at Random) is a situation in which there are missing values in a variable of interest, 
and that missing value is associated with the underlying, unobserved values. This means that a thorough case
study would be skewed. However, if the process causing missing value is MAR, it is conditionally at random. 
In other words, what we saw was a random sampling of the underlying values, conditional on variables. 
Multiple imputation and other imputation approaches function in this scenario because they impute the 
missing values based on the values of other, observable factors.


**MNAR** (Missing Not at Random) is a the situation in which the missing value in a variable of interest is
linked to its unobserved values in a way that is not dependent on or captured by seen variables. There is no
way to recover or estimate the values that the variable would have obtained if it had been entirely observed
in this scenario, and so no imputation method would do a decent job of approximating the whole data. Although
imputation approaches, including multiple imputation, may help to reduce bias in the entire case analysis, no
method can completely remove bias.

In conclusion, in the same dataset, variables that are MCAR which don't need to imputation, and others that are MAR so we can successfully impute them, and variables that are MNAR which there is no imputation would recover the true distribution. 


2. Explain in a couple of sentences how the Multiple Imputation by Chained Equations (MICE) work.

**Solution:**

First select a variable to impute, then randomly complete missing entries for all other variables.
Also, it can the variables as features in the prediction model. Iterate across variables until all have been
imputed. Repeat, starting from the imputed dataset, until convergence.

3. Perform a data quality check of the ICU stays data. Discard variables with substantial missingness, say >5000 `NA`s. Replace apparent data entry errors by `NA`s.

**Solution:**

```{r}
path <- "~/Desktop/Biostats 203B/biostat-203b-2022-winter/hw4"
data <- readRDS("~/Desktop/Biostats 203B/biostat-203b-2022-winter/hw3/mimic_icu_cohort.rds")
rmvar <- c("subject_id", "hadm_id",
             "stay_id", "last_careunit",
             "intime",
             "edregtime","edouttime",
             "outtime","los",
             "dischtime","deathtime",
             "discharge_location",
             "edouttime",
             "hospital_expire_flag",
             "anchor_year","anchor_year_group",
             "dod","anchor_age","admit_to_death","le50960")
data <- data %>% select(-any_of(rmvar))
print(data, width = Inf)
```


```{r, cache=TRUE}
rmcatg <- c( "thirty_day_mort",
             "first_careunit",
             "admission_type",
             "admission_location",
             "insurance",
             "language",
             "marital_status",
             "ethnicity",
             "gender")
data %>%
  select(all_of(rmcatg)) %>%
  ExpCTable(Target = "thirty_day_mort",
            margin=1, clim=10, nlim=3,
            round=2, bin=NULL, per=FALSE)
```


```{r, cache=TRUE}
numvars <- data %>%
  select(-any_of(rmcatg)) %>%
  names()
data %>% 
  select(all_of(numvars), "thirty_day_mort") %>%
  ExpNumStat(by = "G", gp = "thirty_day_mort",
             Qnt = seq(0,1,0.25),
             MesofShape = 1,
             Outlier = TRUE,
             round = 2)
```


```{r, cache=TRUE}
data <- data %>%
  mutate(speaks_english = ifelse(language=="ENGLISH", 1, 0),
         ethnicity =
           case_when(
             ethnicity=="UNABLE TO OBTAIN" ~ "NOT REGISTERED",
             ethnicity=="UNKNOWN" ~ "NOT REGISTERED",
             TRUE ~ ethnicity
           ),
         is_am = lubridate::am(admittime) %>%
           as.numeric(),
         week = lubridate::epiweek(admittime),
         year = lubridate::epiyear(admittime))
data <-  data %>% 
  select(-c("admittime"))
rmcatg <- c(rmcatg[-6], 
             "speaks_english",
             "is_am")
numvars <- c(numvars[-c(1,8,9,20)], 
             "week","year")
```

```{r}
z_scores <- as.data.frame(
  sapply(data %>% 
           select(all_of(numvars)),
         function(df) (abs(df-mean(df,na.rm = TRUE))/sd(df,na.rm = TRUE))))
for(i in numvars){
  aux <- z_scores[,i]
  data[which(aux>=3),i] <- NA
  }
data %>% 
  select(all_of(numvars)) %>%
  summary()
```


4. Impute missing values by `miceRanger` (request $m=3$ data sets). This step is computational intensive.
Make sure to save the imputation results as a file. Hint: Setting `max.depth=10` in the `miceRanger` function
may cut some computing time.

**Solution:**

```{r, eval=FALSE}
data <- data %>%
  select(all_of(numvars),
         all_of(rmcatg))
write_csv(data, "data.csv")
require(miceRanger)
set.seed(2017)
micedata <- miceRanger(data, m=3,
                       returnModels = TRUE,
                       verbose = TRUE,
                       max.depth = 10)
save.image("~/Desktop/Biostats 203B/biostat-203b-2022-winter/hw4/mice.RData")

```

```{r, echo=FALSE}
load("mice.RData")
micedata
summary(micedata)
```


5. Make imputation diagnostic plots and explain what they mean.

**Solution:**

```{r}
plotCorrelations(micedata)
```

From the model correlation plot, this diagnostic does not look great because the correlations are low. 
This probably means that we should run further iterations to develop a good imputation model.

**Solution:**

```{r}
plotModelError(micedata)
```

From the model error plot, for the heart rate variables, sodium, hematocrit and wbc, which are less well
captured by the model.

**Solution:**

```{r}
plotDistributions(micedata, vars='allNumeric')
```

From the numerical variables, heart rate and respiratory rate both are less skewed, but for sodium, which got
a higher spread from the original data.

**Solution:**

```{r}
plotVarConvergence(micedata)
```

From the convergence plot, shows the mean and standard deviation of the imputed values across datasets. It looks okay, so overall it likely would benefit from more iterations. 

**Solution:**

```{r}
plotVarImportance(micedata,
                  display = "Relative",
                  tl.cex = 0.5,
                  tl.col = "black",
                  number.cex = 0.4,
                  cl.pos = "n",
                  #cl.align.text = "l", 
                  type = "upper")
```

From the variable importance plot, shows the weight of each variable when imputing another variable.

**Solution:**

```{r}
plotImputationVariance(micedata, ncol=2, widths=c(6,2))
``` 

For numerical variables are by the standard deviation of the imputed values in each dataset. In the plots,
the shaded area is when the standard deviation of the imputed values is less than the standard deviation of
the original data.

**Solution:**

```{r}
plotDistributions(micedata, vars='allCategorical')
```

From the categorical variables, there are  less married  and more single people. So the model thinks that
for single stauts, they are more likely to have missing their marital status.


6.Choose one of the imputed data sets to be used in Q2. This is **not** a good idea to use just one imputed
data set or to average multiple imputed data sets. Explain in a couple of sentences what the correct Multiple
Imputation strategy is.

**Solution:**

Average numerical and categorical imputed variables from the dataset, then re-assign the names.

```{r, eval = FALSE}
d_lis <- completeData(micedata)
datam <- lapply(seq_along(d_lis),
                function(i) model.matrix(thirty_day_mort ~., data = d_lis[[i]]))
dataname <- colnames(datam[[1]])
datam <- array(unlist(datam), 
               dim = c(nrow(datam[[1]]),ncol(datam[[1]]),3))
datamice <- rowMeans(datam, dims = 2) %>%
  as.data.frame()
names(datamice) <- dataname
write_csv(datamice, "datamice.csv")
```


## Q2. Predicting 30-day mortality

Develop at least two analytic approaches for predicting the 30-day mortality of patients admitted to ICU using demographic information (gender, age, marital status, ethnicity), first lab measurements during ICU stay, and first vital measurements during ICU stay. For example, you can use (1) logistic regression (`glm()` function in base R or keras), (2) logistic regression with lasso penalty (glmnet or keras package), (3) random forest (randomForest package), or (4) neural network (keras package).

1. Partition data into 80% training set and 20% test set. Stratify partitioning according the 30-day mortality status.

**Solution:**

```{r}
icu <- read_csv("~/Desktop/Biostats 203B/biostat-203b-2022-winter/hw4/data.csv")
icu_30 <- icu %>% filter(thirty_day_mort == 1)
icu_30no <- icu %>% filter(thirty_day_mort == 0)
icu2 <- sample(1:nrow(icu_30), size  = 0.8*nrow(icu_30))
icu3 <- icu_30[icu2, ]
icu_test <- icu_30[-icu2, ]
icu2no <- sample(1:nrow(icu_30no), size  = 0.8*nrow(icu_30no))
icu3no <- icu_30no[icu2no, ]
icu_testno <- icu_30no[-icu2no, ]
train <- rbind(icu3, icu3no)
test <- rbind(icu_test, icu_testno)
```

2. Train the models using the training set.

**Solution:**
  
```{r}
#Method 1: logistic regression ----
library(kableExtra)
trainsubset <- train %>%
  select("gender", "age_hadm", "marital_status", "ethnicity", "le50893", 
         "le50902", "le50912","le50931","le50983", "le51221","le220045",
         "le220179","le220181","le220210", "le223761",
         "thirty_day_mort") %>%
  mutate("marital_status" = as.factor(marital_status),
         "ethnicity" = as.factor(ethnicity),
         "female" = ifelse(gender == "F", 1, 0)) %>%
  select(-"gender") %>%
  select("female", everything())
log_reg <- glm(as.factor(thirty_day_mort) ~ ., data = trainsubset, 
               family = binomial (link = "logit"))
kable(log_reg$coefficients, digits=3)
```

3. Compare model prediction performance on the test set.

**Solutions**

``{r}

#logistic regression

log_test = data.frame(probs = predict(log_reg, test, type ="response"))
log_pred = log_test %>%
  mutate(pred = ifelse(probs > .5, 1, 0))
confusionMatrix(as.factor(log_pred$pred),test$trainsubset.thirty_day_mort)
```


