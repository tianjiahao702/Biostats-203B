---
title: "Biostat 203B Homework 4"
subtitle: Due Mar 18 @ 11:59PM
author: Jiahao Tian
output:
  # ioslides_presentation: default
  html_document:
    toc: true
    toc_depth: 4
---

```{r, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
```

Display machine information:
```{r}
sessionInfo()
```
Load database libraries and the tidyverse frontend:
```{r}
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(lubridate))
suppressPackageStartupMessages(library(miceRanger))
```

## Q1. Missing data

Through the Shiny app developed in HW3, we observe abundant missing values in the MIMIC-IV ICU cohort we created. In this question, we use multiple imputation to obtain a data set without missing values.

0. Read following tutorials on the R package miceRanger for imputation: <https://github.com/farrellday/miceRanger>, <https://cran.r-project.org/web/packages/miceRanger/vignettes/miceAlgorithm.html>.

    A more thorough book treatment of the practical imputation strategies is the book [*_Flexible Imputation of Missing Data_*](https://stefvanbuuren.name/fimd/) by Stef van Buuren. 

1. Explain the jargon MCAR, MAR, and MNAR.

**Solution:** 


**MCAR** (Missing Completely at Random) is a situation in which some values on a variable of 
interest are unrecorded, but there is no systematic relationship between that missing value and 
the observed variables or any parameter of interest. This is equivalent to claiming that the complete
instances represent a random sample of the population of interest, making a full case analysis impartial.


**MAR** (Missing at Random) is a situation in which there are missing values in a variable of interest, 
and that missing value is associated with the underlying, unobserved values. This means that a thorough case
study would be skewed. However, if the process causing missing value is MAR, it is conditionally at random. 
In other words, what we saw was a random sampling of the underlying values, conditional on variables. 
Multiple imputation and other imputation approaches function in this scenario because they impute the 
missing values based on the values of other, observable factors.


**MNAR** (Missing Not at Random) is a the situation in which the missing value in a variable of interest is
linked to its unobserved values in a way that is not dependent on or captured by seen variables. There is no
way to recover or estimate the values that the variable would have obtained if it had been entirely observed
in this scenario, and so no imputation method would do a decent job of approximating the whole data. Although
imputation approaches, including multiple imputation, may help to reduce bias in the entire case analysis, no
method can completely remove bias.

In conclusion, in the same dataset, variables that are MCAR which don't need to imputation, and others that are MAR so we can successfully impute them, and variables that are MNAR which there is no imputation would recover the true distribution. 


2. Explain in a couple of sentences how the Multiple Imputation by Chained Equations (MICE) work.

**Solution:**

First select a variable to impute, then randomly complete missing entries for all other variables.
Also, it can the variables as features in the prediction model. Iterate across variables until all have been
imputed. Repeat, starting from the imputed dataset, until convergence.

3. Perform a data quality check of the ICU stays data. Discard variables with substantial missingness, say >5000 `NA`s. Replace apparent data entry errors by `NA`s.

**Solution:**

```{r}

path <- "~/Desktop/Biostats 203B/biostat-203b-2022-winter/hw3"
data <- readRDS(
  "~/Desktop/Biostats 203B/biostat-203b-2022-winter/hw3/mimic_icu_cohort.rds")
# Identify variables to remove
popvar <- c("Gender",
            "Ethnicity", "Language",
            "Insurance", "Marital Status")
data <- data %>% 
  select(-any_of(popvar))
print(data, width = Inf)
```

Now we have `r nrow(data)` observations and `r ncol(data)` variables. Also, it is important to note that the appropriate way of summarizing variables (and, later, of modeling their missingness) would vary for numeric versus categorical variables, so I would explore them separately. Let's first look at the categorical variables, exploring their distribution by the outcome of interest.

```{r, cache=TRUE}
library("SmartEDA")
catvars <- c("thirty_day_mort",
             "first_careunit",
             "admission_type",
             "admission_location",
             "insurance",
             "language",
             "marital_status",
             "ethnicity",
             "gender")
# Create table for categorical variables
data %>%
  select(all_of(catvars)) %>%
  ExpCTable(Target = "thirty_day_mort",
            margin=1, clim=10, nlim=3,
            round=2, bin=NULL, per=FALSE)
```


```{r, cache=TRUE}
numvars <- data %>%
  select(-any_of(catvars)) %>%
  names()
data %>% 
  select(all_of(numvars), "thirty_day_mort") %>%
  ExpNumStat(by = "G", gp = "thirty_day_mort",
             Qnt = seq(0,1,0.25),
             MesofShape = 1,
             Outlier = TRUE,
             round = 2)
```



data <- 
  data %>%
  mutate(speaks_english = 
           ifelse(language=="ENGLISH", 1, 0),
         # Recode as NA in ethnicity
         ethnicity =
           case_when(
             ethnicity=="UNABLE TO OBTAIN" ~ "NOT REGISTERED",
             ethnicity=="UNKNOWN" ~ "NOT REGISTERED",
             TRUE ~ ethnicity
           ),
         # Indicator for having arterial bp
         bp_recorded =
           case_when(
             is.na(Noninvasive blood pressure mean) ~ 0L,
             is.na(arterial_blood_pressure_systolic) ~ 0L,
             TRUE ~ 1L
           ),
         # Indicator for lactate
         lactate_recorded = ifelse(is.na(lactate), 0, 1),
         # Transform admittime
         # To have some seasonality information
         # First, time of the day (am vs pm)
         is_am = lubridate::am(admittime) %>%
           as.numeric(),
         # Epidemiological week
         epi_week = lubridate::epiweek(admittime),
         # Epidemiological year
         epi_year = lubridate::epiyear(admittime))
```
# Remove variables already used
data <- 
  data %>% 
  select(-c("Noninvasive blood pressure mean",
           "Noninvasive blood pressure systolic",
           "lactate",
           "language",
           "admittime"))
# Update our variable listing
# In catvars, replace language by the recoded version
catvars <- c(catvars[-6], # remove language
             "speaks_english",
             "arterial_bp_recorded",
             "lactate_recorded",
             "is_am")
# In numvars, drop used ones and add newly created
# remove admittime, arterial bp, lactate
numvars <- c(numvars[-c(1,8,9,20)], 
             "epi_week","epi_year")
```

We still care about some outliers, as appearing in our exploration (here and in the previous homework). I will use a somewhat common, crude but still useful measure to identify outliers, as $\pm 3 SD$. The reason for this choice is that it is less strict than other alternatives ($\pm 2 SD$, $\pm 1.5\text{ IQR}$), but in the context at hand we would want to allow for some extreme values, while still caughting those that most likely come from errors of measurement. 


4. Impute missing values by `miceRanger` (request $m=3$ data sets). This step is computational intensive. Make sure to save the imputation results as a file. Hint: Setting `max.depth=10` in the `miceRanger` function may cut some computing time.

5. Make imputation diagnostic plots and explain what they mean.

6. Choose one of the imputed data sets to be used in Q2. This is **not** a good idea to use just one imputed data set or to average multiple imputed data sets. Explain in a couple of sentences what the correct Multiple Imputation strategy is.

## Q2. Predicting 30-day mortality

Develop at least two analytic approaches for predicting the 30-day mortality of patients admitted to ICU using demographic information (gender, age, marital status, ethnicity), first lab measurements during ICU stay, and first vital measurements during ICU stay. For example, you can use (1) logistic regression (`glm()` function in base R or keras), (2) logistic regression with lasso penalty (glmnet or keras package), (3) random forest (randomForest package), or (4) neural network (keras package).

1. Partition data into 80% training set and 20% test set. Stratify partitioning according the 30-day mortality status.

2. Train the models using the training set.

3. Compare model prediction performance on the test set.
